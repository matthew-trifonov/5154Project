# Image Captioning Project

The primary goal of this project is to generate captions for images using a combination of Convolutional Neural Networks (CNNs) for image feature extraction and Recurrent Neural Networks (RNNs), specifically LSTM (Long Short-Term Memory), for sequence generation. The model uses the **Flickr8k dataset**, which contains 8,000 images, each paired with five corresponding captions.

This project aims to update and replicate the work of **Katariya, Y. (2017)**, available on GitHub:  
[Image-Captioning GitHub Repository](https://github.com/yashk2810/Image-Captioning).

The content of this repository is made available under the same **license** as the original project. Please refer to the **LICENSE** file for more information about the permissions and restrictions for reuse, redistribution, and modification.

## References

- Katariya, Y. (2017). Image-Captioning. GitHub. https://github.com/yashk2810/Image-Captioning
- Sayan, F. (2020). Flickr8k Dataset. Kaggle. https://www.kaggle.com/datasets/sayanf/flickr8k
